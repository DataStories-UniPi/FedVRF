{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewt/miniforge3/envs/torch/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewt/miniforge3/envs/torch/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator StandardScaler from version 1.2.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vrf_brest = torch.load('lstm_1_350_fc_150_share_all_window_1024_stride_1024_crs_3857___batchsize_1__brest_dataset.pth', map_location=torch.device('cpu'))\n",
    "vrf_norway = torch.load('lstm_1_350_fc_150_share_all_window_1024_stride_1024_crs_3857___batchsize_1__norway_dataset_.pth', map_location=torch.device('cpu'))\n",
    "vrf_piraeus = torch.load('lstm_1_350_fc_150_share_all_window_1024_stride_1024_crs_3857___batchsize_1__piraeus_dataset.pth', map_location=torch.device('cpu'))\n",
    "vrf_mt = torch.load('lstm_1_350_fc_150_share_all_window_1024_stride_1024_crs_3857___batchsize_1__mt_dataset.pth', map_location=torch.device('cpu'))\n",
    "vrf_share_all = torch.load('lstm_1_350_fc_150_share_all_awindow_1024_stride_1024_crs_3857___batchsize_1__share_all.pth', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vrf_brest['scaler'].mean_, vrf_brest['scaler'].scale_, sep='\\t')\n",
    "print(vrf_norway['scaler'].mean_, vrf_norway['scaler'].scale_, sep='\\t')\n",
    "print(vrf_piraeus['scaler'].mean_, vrf_piraeus['scaler'].scale_, sep='\\t')\n",
    "print(vrf_mt['scaler'].mean_, vrf_mt['scaler'].scale_, sep='\\t')\n",
    "print(vrf_share_all['scaler'].mean_, vrf_share_all['scaler'].scale_, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test set of Brest, Norway, and Piraeus Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dataset as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nor_ix, nor_data = pd.read_pickle('./pkl/norway_dataset_train_dev_test_indices.pkl'), pd.read_pickle('./pkl/norway_dataset_window_1024_stride_1024_crs_3857__.traj_delta_windows.pickle')\n",
    "bre_ix, bre_data = pd.read_pickle('./pkl/brest_dataset_train_dev_test_indices.pkl'), pd.read_pickle('./pkl/brest_dataset_window_1024_stride_1024_crs_3857__.traj_delta_windows.pickle')\n",
    "pir_ix, pir_data = pd.read_pickle('./pkl/piraeus_dataset_train_dev_test_indices.pkl'), pd.read_pickle('./pkl/piraeus_dataset_window_1024_stride_1024_crs_3857__.traj_delta_windows.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nor_test_dataset, bre_test_dataset, pir_test_dataset = ds.VRFDataset(\n",
    "    data=nor_data.iloc[nor_ix['test']].copy(), \n",
    "    scaler=vrf_norway['scaler']\n",
    "), ds.VRFDataset(\n",
    "    data=bre_data.iloc[bre_ix['test']].copy(), \n",
    "    scaler=vrf_brest['scaler']\n",
    "), ds.VRFDataset(\n",
    "    data=pir_data.iloc[pir_ix['test']].copy(), \n",
    "    scaler=vrf_piraeus['scaler']\n",
    ")\n",
    "\n",
    "nor_test_loader, bre_test_loader, pir_test_loader = ds.DataLoader(\n",
    "    nor_test_dataset, \n",
    "    batch_size=1, \n",
    "    collate_fn=nor_test_dataset.pad_collate\n",
    "), ds.DataLoader(\n",
    "    bre_test_dataset, \n",
    "    batch_size=1, \n",
    "    collate_fn=bre_test_dataset.pad_collate\n",
    "), ds.DataLoader(\n",
    "    pir_test_dataset, \n",
    "    batch_size=1, \n",
    "    collate_fn=pir_test_dataset.pad_collate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models as ml\n",
    "import train as tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Share-all VRF on Norway Test Set...\n",
      "self.eps=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 7.06312 |  Accuracy: 9.98874 | 8.91934; 416.72978; 531.82347; 958.30709; 956.40897; 1287.60952; nan m\n",
      "Evaluating Share-all VRF on Brest Test Set...\n",
      "self.eps=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 99.34281 |  Accuracy: 140.49193 | 43.08056; 557.39830; 1145.19652; 1594.11798; 3025.55032; 2440.73458; 3515.93491 m\n",
      "Evaluating Share-all VRF on Piraeus Test Set...\n",
      "self.eps=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 65.06891 |  Accuracy: 92.02131 | 39.50148; 475.13291; 927.04572; 1673.22440; 4090.95868; 3172.36473; 4648.08424 m\n"
     ]
    }
   ],
   "source": [
    "for name, loader, scaler in zip(\n",
    "    ['Norway', 'Brest', 'Piraeus'],\n",
    "    [nor_test_loader, bre_test_loader, pir_test_loader], \n",
    "    [vrf_norway['scaler'], vrf_brest['scaler'], vrf_piraeus['scaler']]\n",
    "):\n",
    "    model = ml.VesselRouteForecasting(\n",
    "        hidden_size=350, fc_layers=[150,], scale=dict(mu=torch.tensor(scaler.mean_[:2]), sigma=torch.tensor(scaler.scale_[:2]))\n",
    "    )\n",
    "    model.load_state_dict(vrf_share_all['model_state_dict'])\n",
    "    model.eval()\n",
    "\n",
    "    print(f'Evaluating Share-all VRF on {name} Test Set...')\n",
    "    tr.evaluate_model(model, torch.device('cpu'), criterion=tr.RMSELoss(eps=1e-4), test_loader=loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyTorch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
